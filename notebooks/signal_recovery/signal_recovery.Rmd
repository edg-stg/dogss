---
title: "Signal recovery with dogss"
author: Edgar Steiger
date: 2018
output:
  github_document:
    toc: true
---

This document shows and explains how to use the dogss package and how to reproduce Figures 2 to 8 from the paper (put reference here as a link).

First we need to load some packages that are required for comparisons and plotting (please install if not available on your machine):

```{r packages, message=FALSE}
library(dogss) # our method for sparse-group Bayesian feature selection with EP
library(glmnet) # standard lasso
library(gglasso) # group lasso
library(SGL) # sparse-group lasso
library(MBSGS) # Bayesian feature selection with Gibbs sampling

library(ggplot2) # for nice plots
library(ggthemes) # for even nicer plots
library(grid) # to arrange plots pleasantly

library(DescTools) # for area computations (AUROC, AUPR)
```

Furthermore we need to load three R files with additional code:

```{r additionalfunctions}
source("../auxiliary_rfunctions/my_BSGSSS.R") # MBSGS package has a problem with groups of size 1
source("../auxiliary_rfunctions/my_cvSGL.R") # proper cross validation for SGL package

source("../auxiliary_rfunctions/my_theme.R") # functions to adjust ggplots
```

## Simulation

We show how to simulate data for signal recovery. This data will be used in the next section.

First we set the parameters for simulation. We will also set a seed to produce exactly the needle plot like in the publication:

```{r parameters}
m <- 30; p <- 50; nG <- 10; nzG <- 3; k <- 10; sigma0 <- 1
set.seed(2670)
```

Here **m** is the number of observations, **p** is the number of features, **nG** is the number of groups, **k** is the number of non-zero coefficients and **sigma0** refers to the noise we will add in the end.

```{r}
sim_signalrecovery <- function(m, p, nG, nzG, k, sigma0) {
  betas <- rep(0, p)
  G <- sort(sample(1:nG, p, replace=TRUE))
  while (sum(!(1:nG %in% G)) > 0) { # this makes sure we have exactly nG groups
    G <- sort(sample(1:nG, p, replace=TRUE))
  }
  
  nngroups <- sapply(1:nG, function(g) sum(G==g)) # we will need the group sizes for BSGSSS
  
  X <- matrix(rnorm(m*p, 0, 1), nrow=m, ncol=p)
  nzgroups <- sample(1:nG, nzG)
  whichbeta <- which(G%in%nzgroups)
  betas[sample(whichbeta, min(length(whichbeta), k))] <- runif(min(length(whichbeta), k), -5, 5)
  Y <- as.vector(X %*% betas) + rnorm(m, 0, sigma0)
}
```


## Needle plot

contents (F2)

```{r figure2, fig.height=6, fig.width=7}
results <- list()

results$dogss <- cv_dogss(X,Y,G)
results$ssep <- cv_dogss(X,Y,G=NULL) 
results$lasso <- cv.glmnet(x=X, y=Y, intercept=FALSE, standardize=FALSE)
results$sgl <- my_cvSGL(data=list(x=X,y=Y),index=G, standardize=FALSE)
results$gglasso <- cv.gglasso(x=X, y=Y, group=G, nfolds=10, intercept=FALSE)
results$bsgsss <- my_BSGSSS(Y=Y, X=X, group_size=nngroups)

### lambdamin+1se rule:
index_lasso <- which(results$lasso$lambda==results$lasso$lambda.1se)
index_gglasso <- which(results$gglasso$lambda==results$gglasso$lambda.1se)

mydata_signal <- data.frame(
  index=rep(1:p, times=7),
  BETAS=c(
    results$dogss$m_cv, 
    results$ssep$m_cv, 
    results$sgl$beta,
    results$gglasso$gglasso.fit$beta[, index_gglasso], 
    results$lasso$glmnet.fit$beta[, index_lasso], 
    results$bsgsss$pos_median,
    betas
  ),
  G=as.factor(rep(G,times=7)),
  method=factor(rep(c("dogss", "ssep", "sgl" , "gglasso", "lasso", "bsgsss", "original"), each=p), levels=c("dogss", "ssep", "sgl" , "gglasso", "lasso", "bsgsss", "original"), ordered=TRUE)
)

ggplot(mydata_signal, aes(colour=G, x=index, ymax=BETAS, ymin=0)) +
  facet_wrap(~ method, nrow=4, ncol=2) +
  geom_linerange(size=1.3)  +
  scale_colour_manual(values=rep(Ed_palette,length.out=p)) +
  scale_x_continuous(breaks = c(0.5, cumsum(nngroups[1:(ngroups)])+0.5), expand=c(0,1)) +
  labs(colour = "group", x="index of coefficient", y="value of coefficient") +
  theme_Ed() + theme(plot.title = element_blank(), legend.position = "top", axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.line.x =element_blank())
```


## Three scenarios for feature selection

contents (F3-5)

### small

contents

### medium

contents

### large

contents

## Noise

contents, F6

## Correlation structure

contents, F7

## Slab parameter

contents, F8
